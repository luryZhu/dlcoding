{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c57417c",
   "metadata": {},
   "source": [
    "# 作业3 CNN 食物图片分类\n",
    "参考:https://blog.csdn.net/iteapoy/article/details/105765411\n",
    "\n",
    "通过卷积神经网络（Convolutional Neural Networks, CNN）对食物图片进行分类。\n",
    "\n",
    "数据集中的食物图采集于网上，总共11类：Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles/Pasta, Rice, Seafood, Soup, Vegetable/Fruit. 每一类用一个数字表示。\n",
    "比如：0表示Bread,1,2...10以此类推\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d99c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#依赖\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33e53c",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "下载并解压food-11.zip文件,里面有3个文件夹:\n",
    "    \n",
    "- training: 9866张\n",
    "- validation: 3430张\n",
    "- testing: 3347张\n",
    "\n",
    "训练集和验证集图片,命名格式为: [类别]_[编号].jpg  \n",
    "测试集图片命名格式为: [编号].jpg  \n",
    "输出格式为:\n",
    "```\n",
    "Id,Category  \n",
    "0,0  \n",
    "1,0  \n",
    "2,0  \n",
    "...  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563842c5",
   "metadata": {},
   "source": [
    "### 读取图片\n",
    "用cv2库读取图片,存储在numpy中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241d38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图片\n",
    "def readfile(path,label):\n",
    "    #path  图片路径\n",
    "    #label 布尔值,表示需不需要返回y值\n",
    "    \n",
    "    # 读取目录下所有文件名\n",
    "    image_dir=sorted(os.listdir(path))\n",
    "    # x 存储图片 128x128x3 宽高128像素,RGB3色\n",
    "    x=np.zeros( (len(image_dir),128,128,3), dtype=np.uint8 )\n",
    "    # y 存储label\n",
    "    y=np.zeros( (len(image_dir)), dtype=np.uint8 )\n",
    "    for i,file in enumerate(image_dir):\n",
    "        img=cv2.imread(os.path.join(path,file))\n",
    "        # cv2.resize() 将图片大小统一为128x128\n",
    "        x[i,:,:]=cv2.resize(img,(128,128))\n",
    "        if label:\n",
    "            y[i]=int(file.split(\"_\")[0])\n",
    "    if label:\n",
    "        return x,y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc701c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data ...\n",
      "Size of Training data: 9866\n"
     ]
    }
   ],
   "source": [
    "#读取测试集\n",
    "workspace_dir=\"./food-11\"\n",
    "print(\"Reading data ...\")\n",
    "train_x, train_y = readfile(os.path.join(workspace_dir,\"training\"),True)\n",
    "print(\"Size of Training data: {}\".format(len(train_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598a5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Validation data: 3430\n"
     ]
    }
   ],
   "source": [
    "val_x, val_y = readfile(os.path.join(workspace_dir,\"validation\"),True)\n",
    "print(\"Size of Validation data: {}\".format(len(val_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f862f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of testing: 3347\n"
     ]
    }
   ],
   "source": [
    "test_x = readfile(os.path.join(workspace_dir,\"testing\"),False)\n",
    "print(\"Size of testing: {}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba2357",
   "metadata": {},
   "source": [
    "### 定义Dataset\n",
    "Dataset 需要 overload 两个函数：__len__ 及 __getitem__\n",
    "\n",
    "__len__ 必须要传回 dataset 的大小\n",
    "__getitem__ 则定义了当函数利用 [ ] 取值时，dataset 应该要怎么传回数据。\n",
    "实际上，在我们的代码中并不会直接使用到这两个函数，但是当 DataLoader 在 enumerate Dataset 时会使用到，如果没有这样做，程序运行阶段会报错。\n",
    "\n",
    "这里还对图片进行了数据增强。transforms表示对图片的预处理方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a13498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training 时，通过随机旋转、水平翻转图片来进行数据增强（data augmentation）\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), #随机翻转图片\n",
    "    transforms.RandomRotation(15), #随机旋转图片\n",
    "    transforms.ToTensor(), #将图片变成 Tensor，并且把数值normalize到[0,1]\n",
    "])\n",
    "#testing 时，不需要进行数据增强（data augmentation）\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(), #将图片变成 Tensor，并且把数值normalize到[0,1]\n",
    "])\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label 需要是 LongTensor 型\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            #None表示空,y非空时,转换为LongTensor 型\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71d6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_set= ImgDataset(train_x,train_y,train_transform)\n",
    "val_set= ImgDataset(val_x,val_y,test_transform)\n",
    "# 调用DataLoader,传入训练DataSet,batch size,每个epoch前做一次数据重排\n",
    "train_loader=DataLoader(train_set,batch_size=batch_size, shuffle=True)\n",
    "val_loader=DataLoader(val_set,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efcc57",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "卷积神经网络CNN+全连接前向传播神经网络FC  \n",
    "\n",
    "CNN的每一层的结构是:\n",
    "- 卷积层cov\n",
    "- 标准池化层 batchnorm\n",
    "- 激活函数 Relu\n",
    "- 最大池化层 MaxPllo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b57e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier,self).__init__()\n",
    "        # CNN\n",
    "        # input 3x128x128\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        #torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 3个input channel,64个3x3 filter,stride为1,padding为1\n",
    "            nn.Conv2d(3,64,3,1,1),  #输出64x128x128,因为padding+2,3x3-2\n",
    "            nn.BatchNorm2d(64),     #channel数为64,归一化\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), #2x2 ,stride=2 输出64x64x64\n",
    "            \n",
    "            nn.Conv2d(64,128,3,1,1),  #输出128x64x64\n",
    "            nn.BatchNorm2d(128),     \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), #输出128x32x32\n",
    "            \n",
    "            nn.Conv2d(128,256,3,1,1),  #输出256x32x32\n",
    "            nn.BatchNorm2d(256),     \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), #输出256x16x16\n",
    "            \n",
    "            nn.Conv2d(256,512,3,1,1),  #输出512x16x16\n",
    "            nn.BatchNorm2d(512), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), #输出512x8x8\n",
    "            \n",
    "            nn.Conv2d(512,512,3,1,1),  #输出512x8x8\n",
    "            nn.BatchNorm2d(512), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), #输出512x4x4\n",
    "        )\n",
    "        \n",
    "        #FC\n",
    "        # input 512x4x4 flatten以后输入\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(512*4*4,1024), #输出1024维\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,11),    #输出11维,分类结果\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.cnn(x)\n",
    "        out=out.view(out.size()[0],-1) #flatten\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf8a0ce",
   "metadata": {},
   "source": [
    "## 训练\n",
    "用training set训练,并用validation set选择最好的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bd3e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 2.00 GiB total capacity; 1020.97 MiB already allocated; 75.35 MiB free; 1.00 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13408/2518153849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# data[0]是X data[1]是Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptmizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#optim内置函数,把梯度归0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtrain_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#实际上是调用forward函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#需要参数同在GPU上才能运算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#计算gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13408/4027430900.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 2.00 GiB total capacity; 1020.97 MiB already allocated; 75.35 MiB free; 1.00 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model=Classifier().cuda() #GPU加速\n",
    "loss=nn.CrossEntropyLoss() #分类,使用交叉熵计算损失函数\n",
    "# CrossEntrophyLoss toolkit里面包含了逻辑回归和softmax,直接就可以分类\n",
    "optmizer=torch.optim.Adam(model.parameters(),lr=0.001)#优化器Adam 学习速率\n",
    "num_epoch=30 #迭代次数\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time=time.time()\n",
    "    #初始化准确率和损失为0\n",
    "    train_acc=0.0\n",
    "    train_loss=0.0\n",
    "    val_acc=0.0\n",
    "    val_loss=0.0\n",
    "    \n",
    "    #训练模型\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        # data[0]是X data[1]是Y\n",
    "        optmizer.zero_grad() #optim内置函数,把梯度归0\n",
    "        train_pred=model(data[0].cuda()) #实际上是调用forward函数\n",
    "        batch_loss=loss(train_pred,data[1].cuda()) #需要参数同在GPU上才能运算\n",
    "        batch_loss.backward() #计算gradient\n",
    "        optmizer.step() #optimizer用gradient更新参数\n",
    "        \n",
    "        #计算准确率 predict输出值是11维数组,argmax取得组大值的对应索引\n",
    "        #索引值即分类结果,跟label比较\n",
    "        train_acc+=np.sum(np.argmax(\n",
    "            train_pred.cpu().data.numpy(),axis=1)==data[1].numpy())\n",
    "        #计算损失函数,item返回浮点型数据\n",
    "        train_loss+=batch_loss.item()\n",
    "        \n",
    "    #验证集 评估模型\n",
    "    \n",
    "    #一键搞定Batch Normalization和Dropout\n",
    "    model.eval()\n",
    "    #在使用pytorch时，并不是所有的操作都需要进行计算图的生成（计算过程的构建，以便梯度反向传播等操作）。\n",
    "    #而对于tensor的计算操作，默认是要进行计算图的构建的，\n",
    "    #在这种情况下，可以使用 with torch.no_grad():\n",
    "    #强制之后的内容不进行计算图构建。\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(val_loader):\n",
    "            val_pred=model(data[0].cuda())\n",
    "            batch_loss=loss(val_pred,data[1].cuda())\n",
    "            \n",
    "            val_acc+=np.sum(np.argmax(\n",
    "                val_pred.cpu().data.numpy(),axis=1)==data[1].numpy())\n",
    "            val_loss+=batch_loss.detach().numpy()\n",
    "            \n",
    "        #打印结果\n",
    "        print('[{}/{}] {:.2f} sec(s) Train Acc: {:.6f} Loss: {:.6f} | Val Acc: {:.6f} loss: {:.6f}'.format(\n",
    "            epoch + 1, \n",
    "            num_epoch,\n",
    "            time.time()-epoch_start_time,\n",
    "            train_acc/train_set.__len__(), \n",
    "            train_loss/train_set.__len__(),\n",
    "            val_acc/val_set.__len__(), \n",
    "            val_loss/val_set.__len__()))\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260a5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
